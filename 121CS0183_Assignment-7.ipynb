{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12ed8dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb4147fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('DelhiAQI.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17587b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PM2.5</th>\n",
       "      <th>PM10</th>\n",
       "      <th>NO</th>\n",
       "      <th>NO2</th>\n",
       "      <th>NOx</th>\n",
       "      <th>NH3</th>\n",
       "      <th>CO</th>\n",
       "      <th>SO2</th>\n",
       "      <th>O3</th>\n",
       "      <th>Benzene</th>\n",
       "      <th>Toluene</th>\n",
       "      <th>Xylene</th>\n",
       "      <th>AQI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>454.58</td>\n",
       "      <td>935.18</td>\n",
       "      <td>81.52</td>\n",
       "      <td>41.78</td>\n",
       "      <td>187.66</td>\n",
       "      <td>27.54</td>\n",
       "      <td>9.29</td>\n",
       "      <td>3.41</td>\n",
       "      <td>54.94</td>\n",
       "      <td>25.24</td>\n",
       "      <td>58.57</td>\n",
       "      <td>13.80</td>\n",
       "      <td>653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>440.44</td>\n",
       "      <td>935.18</td>\n",
       "      <td>70.80</td>\n",
       "      <td>43.46</td>\n",
       "      <td>176.83</td>\n",
       "      <td>27.72</td>\n",
       "      <td>13.28</td>\n",
       "      <td>3.88</td>\n",
       "      <td>50.53</td>\n",
       "      <td>23.10</td>\n",
       "      <td>49.37</td>\n",
       "      <td>15.63</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>409.09</td>\n",
       "      <td>935.18</td>\n",
       "      <td>132.46</td>\n",
       "      <td>41.19</td>\n",
       "      <td>141.02</td>\n",
       "      <td>28.94</td>\n",
       "      <td>29.67</td>\n",
       "      <td>2.83</td>\n",
       "      <td>19.33</td>\n",
       "      <td>19.04</td>\n",
       "      <td>38.94</td>\n",
       "      <td>17.18</td>\n",
       "      <td>532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>436.12</td>\n",
       "      <td>935.18</td>\n",
       "      <td>84.78</td>\n",
       "      <td>39.55</td>\n",
       "      <td>102.84</td>\n",
       "      <td>29.30</td>\n",
       "      <td>21.76</td>\n",
       "      <td>4.33</td>\n",
       "      <td>20.08</td>\n",
       "      <td>13.99</td>\n",
       "      <td>27.53</td>\n",
       "      <td>16.82</td>\n",
       "      <td>561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>415.88</td>\n",
       "      <td>976.99</td>\n",
       "      <td>60.24</td>\n",
       "      <td>37.41</td>\n",
       "      <td>80.12</td>\n",
       "      <td>30.84</td>\n",
       "      <td>26.19</td>\n",
       "      <td>6.17</td>\n",
       "      <td>16.00</td>\n",
       "      <td>11.14</td>\n",
       "      <td>21.99</td>\n",
       "      <td>14.29</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PM2.5    PM10      NO    NO2     NOx    NH3     CO   SO2     O3  Benzene  \\\n",
       "0  454.58  935.18   81.52  41.78  187.66  27.54   9.29  3.41  54.94    25.24   \n",
       "1  440.44  935.18   70.80  43.46  176.83  27.72  13.28  3.88  50.53    23.10   \n",
       "2  409.09  935.18  132.46  41.19  141.02  28.94  29.67  2.83  19.33    19.04   \n",
       "3  436.12  935.18   84.78  39.55  102.84  29.30  21.76  4.33  20.08    13.99   \n",
       "4  415.88  976.99   60.24  37.41   80.12  30.84  26.19  6.17  16.00    11.14   \n",
       "\n",
       "   Toluene  Xylene  AQI  \n",
       "0    58.57   13.80  653  \n",
       "1    49.37   15.63  645  \n",
       "2    38.94   17.18  532  \n",
       "3    27.53   16.82  561  \n",
       "4    21.99   14.29  567  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "784c798a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.42588175,  5.27561435,  1.07934007, ...,  4.19721961,\n",
       "         3.17072104,  3.87542458],\n",
       "       [ 4.24239721,  5.27561435,  0.83951094, ...,  3.37699166,\n",
       "         3.65270076,  3.79199029],\n",
       "       [ 3.83559097,  5.27561435,  2.21897586, ...,  2.44710279,\n",
       "         4.06093494,  2.61348099],\n",
       "       ...,\n",
       "       [-0.81199194, -0.35107535, -0.3312221 , ..., -0.12324198,\n",
       "        -0.45861257, -0.94290547],\n",
       "       [-0.57465586, -0.31231054, -0.30437556, ..., -0.39873159,\n",
       "        -0.46388011, -0.96376405],\n",
       "       [-0.55726765, -0.24918776, -0.34710631, ..., -0.33810605,\n",
       "        -0.46388011, -0.96376405]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(data)\n",
    "data_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64a5cde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.6 * len(data_scaled))\n",
    "val_size = int(0.2 * len(data_scaled))\n",
    "test_size = len(data_scaled) - train_size - val_size\n",
    "\n",
    "X_train, y_train = data_scaled[:train_size, :-1], data_scaled[:train_size, -1]\n",
    "X_val, y_val = data_scaled[train_size:train_size+val_size, :-1], data_scaled[train_size:train_size+val_size, -1]\n",
    "X_test, y_test = data_scaled[train_size+val_size:, :-1], data_scaled[train_size+val_size:, -1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4101dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the scaler on the training data only and transform the training, validation, and test sets\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7cfda73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 4.19602887,  5.06772012,  1.06443688, ...,  5.92959982,\n",
       "         4.34772925,  2.39477984],\n",
       "       [ 4.01767733,  5.06772012,  0.82132007, ...,  5.3390256 ,\n",
       "         3.5082145 ,  2.79811038],\n",
       "       [ 3.62225152,  5.06772012,  2.21969529, ...,  4.21859038,\n",
       "         2.55646029,  3.13972914],\n",
       "       ...,\n",
       "       [ 2.01103327,  1.54038735,  4.54495335, ...,  1.3926651 ,\n",
       "         1.28532546, -0.64232114],\n",
       "       [ 2.38905277,  1.83959148,  4.97857214, ...,  1.5444482 ,\n",
       "         1.43954067, -0.64672913],\n",
       "       [ 2.33973491,  1.44887893,  4.27462197, ...,  1.46441711,\n",
       "         1.43497809, -0.64672913]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90fc46bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.01229459,  1.42463684,  2.67826077, ...,  1.35126971,\n",
       "         1.4979417 , -0.64672913],\n",
       "       [ 1.93283103,  1.64769316,  3.17220518, ...,  1.35126971,\n",
       "         1.52440466, -0.64672913],\n",
       "       [ 1.99123044,  1.54686646,  3.12956902, ...,  1.28503709,\n",
       "         1.40395255, -0.64672913],\n",
       "       ...,\n",
       "       [ 1.13113202,  3.71322084,  2.82726053, ...,  3.5700626 ,\n",
       "         5.07500452, -0.64232114],\n",
       "       [ 1.57801994,  2.56940203,  5.00170452, ...,  4.80916461,\n",
       "         4.90710157, -0.64672913],\n",
       "       [ 0.99352131,  3.36407655,  3.51646946, ...,  5.14308742,\n",
       "         5.02025356, -0.64672913]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a26428e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.58384252,  3.11597736,  4.25670572, ...,  5.0740951 ,\n",
       "         4.78026185, -0.64672913],\n",
       "       [ 1.02707259,  3.24097335,  3.40534331, ...,  4.76500952,\n",
       "         4.39335505, -0.64672913],\n",
       "       [ 0.65523359,  0.69118633,  1.69604165, ...,  4.90575385,\n",
       "         4.3678046 , -0.64672913],\n",
       "       ...,\n",
       "       [-0.89531487, -0.44811893, -0.36546189, ..., -0.10032863,\n",
       "        -0.07432342, -0.64232114],\n",
       "       [-0.66461828, -0.41011782, -0.33824732, ..., -0.35146066,\n",
       "        -0.35629087, -0.64672913],\n",
       "       [-0.64771651, -0.34823862, -0.38156384, ..., -0.38181728,\n",
       "        -0.29423978, -0.64672913]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1977199e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "195000"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_scaled.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad0bfc03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "286d852e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f890599a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c44e47e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data.drop(columns=['AQI'])\n",
    "y = data['AQI']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_normalized, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cd934e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9fed65cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Dense(Layer):\n",
    "# ...\n",
    "#     def __init__(self, units,\n",
    "#                  activation=None,\n",
    "#                  use_bias=True,\n",
    "#                  kernel_initializer='glorot_uniform',\n",
    "#                  bias_initializer='zeros',\n",
    "#                  kernel_regularizer=None,\n",
    "#                  bias_regularizer=None,\n",
    "#                  activity_regularizer=None,\n",
    "#                  kernel_constraint=None,\n",
    "#                  bias_constraint=None,\n",
    "#                  **kwargs):\n",
    "\n",
    "#  keras uses Glorot initialization with a uniform distribution.r = √(3/fan_avg)\n",
    "\n",
    "def build_model_1():\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(32, activation='sigmoid', kernel_initializer='glorot_uniform', input_shape=(X_train.shape[1],)),\n",
    "        layers.Dense(16, activation='relu', kernel_initializer='he_uniform'),\n",
    "        layers.Dense(1, activation='relu', kernel_initializer='he_uniform')\n",
    "    ])\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.01), loss='mse')\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c2ae827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_2():\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(32, activation='sigmoid', kernel_initializer='glorot_uniform', input_shape=(X_train.shape[1],)),\n",
    "        layers.Dense(8, activation='sigmoid', kernel_initializer='glorot_normal'),\n",
    "        layers.Dense(1, activation='relu', kernel_initializer='he_uniform')\n",
    "    ])\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.01), loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "590c87b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, batch_size, epochs):\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02f0b389",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models, optimizers\n",
    "def evaluate_model(build_model_fn, batch_size, epochs, layer_to_extract):\n",
    "    rmses = []\n",
    "    for _ in range(5):\n",
    "        model = train_model(build_model_fn(), batch_size, epochs)\n",
    "        \n",
    "        y_pred = model.predict(X_test).flatten()\n",
    "\n",
    "        y_pred_denorm = y_pred * scaler.scale_[-1] + scaler.mean_[-1]\n",
    "        y_test_denorm = y_test * scaler.scale_[-1] + scaler.mean_[-1]\n",
    "        \n",
    "        rmse = compute_rmse(y_test_denorm, y_pred_denorm)\n",
    "        rmses.append(rmse)\n",
    "    \n",
    "    return np.mean(rmses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "55d5fc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_svr(X, y):\n",
    "    svr = SVR(kernel='rbf')\n",
    "    svr.fit(X, y)\n",
    "    return svr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5dff52f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(model, X, layer_index):\n",
    "    feature_extractor = models.Model(inputs=model.input, outputs=model.layers[layer_index].output)\n",
    "    return feature_extractor.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "55ac090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_pca(X, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    return pca.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60d5e66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47631d3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python 311\\New folder\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python 311\\New folder\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python 311\\New folder\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python 311\\New folder\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python 311\\New folder\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Mean RMSE for Model-1: 388.01187393364586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python 311\\New folder\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python 311\\New folder\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python 311\\New folder\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python 311\\New folder\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python 311\\New folder\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m94/94\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "Mean RMSE for Model-2: 576.0717450010847\n"
     ]
    }
   ],
   "source": [
    "rmse_model_1 = evaluate_model(build_model_1, batch_size=16, epochs=20, layer_to_extract=1)\n",
    "print(f'Mean RMSE for Model-1: {rmse_model_1}')\n",
    "\n",
    "rmse_model_2 = evaluate_model(build_model_2, batch_size=8, epochs=20, layer_to_extract=1)\n",
    "print(f'Mean RMSE for Model-2: {rmse_model_2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aaf196cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_3():\n",
    "    model_1 = train_model(build_model_1(), batch_size=16, epochs=20)\n",
    "    model_2 = train_model(build_model_2(), batch_size=8, epochs=20)\n",
    "    \n",
    "    features_model_1 = extract_features(model_1, X_train, 1)  \n",
    "    features_model_2 = extract_features(model_2, X_train, 1) \n",
    "    \n",
    "    combined_features = np.hstack((features_model_1, features_model_2))\n",
    "    \n",
    "    svr = train_svr(combined_features, y_train)\n",
    "    y_pred = svr.predict(np.hstack((extract_features(model_1, X_test, 1), extract_features(model_2, X_test, 1))))\n",
    "    \n",
    "    y_pred_denorm = y_pred * scaler.scale_[-1] + scaler.mean_[-1]\n",
    "    y_test_denorm = y_test * scaler.scale_[-1] + scaler.mean_[-1]\n",
    "    \n",
    "    return compute_rmse(y_test_denorm, y_pred_denorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3433a607",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The layer sequential_12 has never been called and thus has no defined input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rmse_model_3 \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model_3\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMean RMSE for Model-3: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrmse_model_3\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[25], line 5\u001b[0m, in \u001b[0;36mevaluate_model_3\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m model_1 \u001b[38;5;241m=\u001b[39m train_model(build_model_1(), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m      3\u001b[0m model_2 \u001b[38;5;241m=\u001b[39m train_model(build_model_2(), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m features_model_1 \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \n\u001b[0;32m      6\u001b[0m features_model_2 \u001b[38;5;241m=\u001b[39m extract_features(model_2, X_train, \u001b[38;5;241m1\u001b[39m) \n\u001b[0;32m      8\u001b[0m combined_features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack((features_model_1, features_model_2))\n",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(model, X, layer_index)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_features\u001b[39m(model, X, layer_index):\n\u001b[1;32m----> 2\u001b[0m     feature_extractor \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m, outputs\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mlayers[layer_index]\u001b[38;5;241m.\u001b[39moutput)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m feature_extractor\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "File \u001b[1;32mC:\\Python 311\\New folder\\Lib\\site-packages\\keras\\src\\ops\\operation.py:228\u001b[0m, in \u001b[0;36mOperation.input\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minput\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    220\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Retrieves the input tensor(s) of a symbolic operation.\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \n\u001b[0;32m    222\u001b[0m \u001b[38;5;124;03m    Only returns the tensor(s) corresponding to the *first time*\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;124;03m        Input tensor or list of input tensors.\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_node_attribute_at_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_tensors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python 311\\New folder\\Lib\\site-packages\\keras\\src\\ops\\operation.py:259\u001b[0m, in \u001b[0;36mOperation._get_node_attribute_at_index\u001b[1;34m(self, node_index, attr, attr_name)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Private utility to retrieves an attribute (e.g. inputs) from a node.\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \n\u001b[0;32m    245\u001b[0m \u001b[38;5;124;03mThis is used to implement the properties:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;124;03m    The operation's attribute `attr` at the node of index `node_index`.\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes:\n\u001b[1;32m--> 259\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has never been called \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand thus has no defined \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    262\u001b[0m     )\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes) \u001b[38;5;241m>\u001b[39m node_index:\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to get \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at node \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but the operation has only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    267\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m inbound nodes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    268\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The layer sequential_12 has never been called and thus has no defined input."
     ]
    }
   ],
   "source": [
    "rmse_model_3 = evaluate_model_3()\n",
    "print(f'Mean RMSE for Model-3: {rmse_model_3}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "08345b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model_4(n_components):\n",
    "    model_1 = train_model(build_model_1(), batch_size=16, epochs=20)\n",
    "    model_2 = train_model(build_model_2(), batch_size=8, epochs=20)\n",
    "    \n",
    "    features_model_1 = extract_features(model_1, X_train, 1)  \n",
    "    features_model_2 = extract_features(model_2, X_train, 1)  \n",
    "    \n",
    "    combined_features = np.hstack((features_model_1, features_model_2))\n",
    "    \n",
    "    reduced_features = apply_pca(combined_features, n_components=n_components)\n",
    "    \n",
    "    svr = train_svr(reduced_features, y_train)\n",
    "    y_pred = svr.predict(apply_pca(np.hstack((extract_features(model_1, X_test, 1), extract_features(model_2, X_test, 1))), n_components))\n",
    "    \n",
    "    y_pred_denorm = y_pred * scaler.scale_[-1] + scaler.mean_[-1]\n",
    "    y_test_denorm = y_test * scaler.scale_[-1] + scaler.mean_[-1]\n",
    "    \n",
    "    return compute_rmse(y_test_denorm, y_pred_denorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef965949",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The layer sequential_14 has never been called and thus has no defined input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m rmse_model_4_8 \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_model_4\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m rmse_model_4_10 \u001b[38;5;241m=\u001b[39m evaluate_model_4(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m      3\u001b[0m rmse_model_4_12 \u001b[38;5;241m=\u001b[39m evaluate_model_4(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\n",
      "Cell \u001b[1;32mIn[30], line 5\u001b[0m, in \u001b[0;36mevaluate_model_4\u001b[1;34m(n_components)\u001b[0m\n\u001b[0;32m      2\u001b[0m model_1 \u001b[38;5;241m=\u001b[39m train_model(build_model_1(), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[0;32m      3\u001b[0m model_2 \u001b[38;5;241m=\u001b[39m train_model(build_model_2(), batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m features_model_1 \u001b[38;5;241m=\u001b[39m \u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \n\u001b[0;32m      6\u001b[0m features_model_2 \u001b[38;5;241m=\u001b[39m extract_features(model_2, X_train, \u001b[38;5;241m1\u001b[39m)  \n\u001b[0;32m      8\u001b[0m combined_features \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack((features_model_1, features_model_2))\n",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m, in \u001b[0;36mextract_features\u001b[1;34m(model, X, layer_index)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_features\u001b[39m(model, X, layer_index):\n\u001b[1;32m----> 2\u001b[0m     feature_extractor \u001b[38;5;241m=\u001b[39m models\u001b[38;5;241m.\u001b[39mModel(inputs\u001b[38;5;241m=\u001b[39m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m, outputs\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mlayers[layer_index]\u001b[38;5;241m.\u001b[39moutput)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m feature_extractor\u001b[38;5;241m.\u001b[39mpredict(X)\n",
      "File \u001b[1;32mC:\\Python 311\\New folder\\Lib\\site-packages\\keras\\src\\ops\\operation.py:228\u001b[0m, in \u001b[0;36mOperation.input\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minput\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    220\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Retrieves the input tensor(s) of a symbolic operation.\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \n\u001b[0;32m    222\u001b[0m \u001b[38;5;124;03m    Only returns the tensor(s) corresponding to the *first time*\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[38;5;124;03m        Input tensor or list of input tensors.\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 228\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_node_attribute_at_index\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_tensors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python 311\\New folder\\Lib\\site-packages\\keras\\src\\ops\\operation.py:259\u001b[0m, in \u001b[0;36mOperation._get_node_attribute_at_index\u001b[1;34m(self, node_index, attr, attr_name)\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Private utility to retrieves an attribute (e.g. inputs) from a node.\u001b[39;00m\n\u001b[0;32m    244\u001b[0m \n\u001b[0;32m    245\u001b[0m \u001b[38;5;124;03mThis is used to implement the properties:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[38;5;124;03m    The operation's attribute `attr` at the node of index `node_index`.\u001b[39;00m\n\u001b[0;32m    257\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes:\n\u001b[1;32m--> 259\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe layer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m has never been called \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mand thus has no defined \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    262\u001b[0m     )\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes) \u001b[38;5;241m>\u001b[39m node_index:\n\u001b[0;32m    264\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAsked to get \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m at node \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but the operation has only \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    267\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inbound_nodes)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m inbound nodes.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    268\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: The layer sequential_14 has never been called and thus has no defined input."
     ]
    }
   ],
   "source": [
    "rmse_model_4_8 = evaluate_model_4(n_components=8)\n",
    "rmse_model_4_10 = evaluate_model_4(n_components=10)\n",
    "rmse_model_4_12 = evaluate_model_4(n_components=12)\n",
    "\n",
    "print(f'Mean RMSE for Model-4 (8 components): {rmse_model_4_8}')\n",
    "print(f'Mean RMSE for Model-4 (10 components): {rmse_model_4_10}')\n",
    "print(f'Mean RMSE for Model-4 (12 components): {rmse_model_4_12}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff9d413",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "\n",
    "data = pd.read_csv('./DelhiAQI.csv')\n",
    "\n",
    "X = data.drop(columns=['AQI'])\n",
    "y = data['AQI']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_normalized, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "def build_model_1():\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(32, activation='sigmoid', kernel_initializer='glorot_uniform', input_shape=(X_train.shape[1],)),\n",
    "        layers.Dense(16, activation='relu', kernel_initializer='he_uniform'),\n",
    "        layers.Dense(1, activation='relu', kernel_initializer='he_uniform')\n",
    "    ])\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.01), loss='mse')\n",
    "    return model\n",
    "\n",
    "def build_model_2():\n",
    "    model = models.Sequential([\n",
    "        layers.Dense(32, activation='sigmoid', kernel_initializer='glorot_uniform', input_shape=(X_train.shape[1],)),\n",
    "        layers.Dense(8, activation='sigmoid', kernel_initializer='glorot_normal'),\n",
    "        layers.Dense(1, activation='relu', kernel_initializer='he_uniform')\n",
    "    ])\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=0.01), loss='mse')\n",
    "    return model\n",
    "\n",
    "def train_model(model, batch_size, epochs):\n",
    "    model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=batch_size, epochs=epochs, verbose=0)\n",
    "    return model\n",
    "\n",
    "def extract_features(model, X, layer_index):\n",
    "    feature_extractor = models.Model(inputs=model.input, outputs=model.layers[layer_index].output)\n",
    "    return feature_extractor.predict(X)\n",
    "\n",
    "def train_svr(X, y):\n",
    "    svr = SVR(kernel='rbf')\n",
    "    svr.fit(X, y)\n",
    "    return svr\n",
    "\n",
    "def apply_pca(X, n_components):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    return pca.fit_transform(X)\n",
    "\n",
    "def compute_rmse(y_true, y_pred):\n",
    "    return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "\n",
    "def evaluate_model(build_model_fn, batch_size, epochs, layer_to_extract):\n",
    "    rmses = []\n",
    "    for _ in range(5):\n",
    "        model = train_model(build_model_fn(), batch_size, epochs)\n",
    "        \n",
    "        y_pred = model.predict(X_test).flatten()\n",
    "\n",
    "        y_pred_denorm = y_pred * scaler.scale_[-1] + scaler.mean_[-1]\n",
    "        y_test_denorm = y_test * scaler.scale_[-1] + scaler.mean_[-1]\n",
    "        \n",
    "        rmse = compute_rmse(y_test_denorm, y_pred_denorm)\n",
    "        rmses.append(rmse)\n",
    "    \n",
    "    return np.mean(rmses)\n",
    "\n",
    "rmse_model_1 = evaluate_model(build_model_1, batch_size=16, epochs=20, layer_to_extract=1)\n",
    "print(f'Mean RMSE for Model-1: {rmse_model_1}')\n",
    "\n",
    "rmse_model_2 = evaluate_model(build_model_2, batch_size=8, epochs=20, layer_to_extract=1)\n",
    "print(f'Mean RMSE for Model-2: {rmse_model_2}')\n",
    "\n",
    "def evaluate_model_3():\n",
    "    model_1 = train_model(build_model_1(), batch_size=16, epochs=20)\n",
    "    model_2 = train_model(build_model_2(), batch_size=8, epochs=20)\n",
    "    \n",
    "    features_model_1 = extract_features(model_1, X_train, 1)  \n",
    "    features_model_2 = extract_features(model_2, X_train, 1) \n",
    "    \n",
    "    combined_features = np.hstack((features_model_1, features_model_2))\n",
    "    \n",
    "    svr = train_svr(combined_features, y_train)\n",
    "    y_pred = svr.predict(np.hstack((extract_features(model_1, X_test, 1), extract_features(model_2, X_test, 1))))\n",
    "    \n",
    "    y_pred_denorm = y_pred * scaler.scale_[-1] + scaler.mean_[-1]\n",
    "    y_test_denorm = y_test * scaler.scale_[-1] + scaler.mean_[-1]\n",
    "    \n",
    "    return compute_rmse(y_test_denorm, y_pred_denorm)\n",
    "\n",
    "rmse_model_3 = evaluate_model_3()\n",
    "print(f'Mean RMSE for Model-3: {rmse_model_3}')\n",
    "\n",
    "def evaluate_model_4(n_components):\n",
    "    model_1 = train_model(build_model_1(), batch_size=16, epochs=20)\n",
    "    model_2 = train_model(build_model_2(), batch_size=8, epochs=20)\n",
    "    \n",
    "    features_model_1 = extract_features(model_1, X_train, 1)  \n",
    "    features_model_2 = extract_features(model_2, X_train, 1)  \n",
    "    \n",
    "    combined_features = np.hstack((features_model_1, features_model_2))\n",
    "    \n",
    "    reduced_features = apply_pca(combined_features, n_components=n_components)\n",
    "    \n",
    "    svr = train_svr(reduced_features, y_train)\n",
    "    y_pred = svr.predict(apply_pca(np.hstack((extract_features(model_1, X_test, 1), extract_features(model_2, X_test, 1))), n_components))\n",
    "    \n",
    "    y_pred_denorm = y_pred * scaler.scale_[-1] + scaler.mean_[-1]\n",
    "    y_test_denorm = y_test * scaler.scale_[-1] + scaler.mean_[-1]\n",
    "    \n",
    "    return compute_rmse(y_test_denorm, y_pred_denorm)\n",
    "\n",
    "rmse_model_4_8 = evaluate_model_4(n_components=8)\n",
    "rmse_model_4_10 = evaluate_model_4(n_components=10)\n",
    "rmse_model_4_12 = evaluate_model_4(n_components=12)\n",
    "\n",
    "print(f'Mean RMSE for Model-4 (8 components): {rmse_model_4_8}')\n",
    "print(f'Mean RMSE for Model-4 (10 components): {rmse_model_4_10}')\n",
    "print(f'Mean RMSE for Model-4 (12 components): {rmse_model_4_12}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a4f407b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa7c4c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b465606",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844de911",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b92ce5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
